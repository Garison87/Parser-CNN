import time
import os
import re
import os.path
import requests
import urllib.request
from PIL import Image
from bs4 import BeautifulSoup


date = time.strftime('%d.%m.%Y')


def create_html_fail(url, title):
    """ Скачивание html страницы """

    try:
        os.makedirs(f'{date}/{title}')
    except FileExistsError:
        pass
    html = requests.get(url)
    with open(f"{date}/{title}/article_html.html", 'wb') as file:
        file.write(html.content)


def get_article(title):
    """ Создание txt файла со статьёй """

    with open(f"{date}/{title}/article_html.html", 'r', encoding="utf-8") as file:
        soup = BeautifulSoup(file.read(), 'html.parser')
        article = soup.select('body')[0].find('main').select('p')
        img = urllib.request.urlopen(soup.select('body')[0].find('main').find('img')['src']).read()
        # article_2 = soup.select('body')[0].find("article").select('p')
        # img = urllib.request.urlopen(soup.select('body')[0].find('article'))
        # img = soup.select('body')[0].find('article').find('section').find_all('img')
        with open(f"{date}/{title}/img_article.jpeg", 'wb') as file_img:
            file_img.write(img)
        with open(f"{date}/{title}/article.txt", 'w', encoding='utf-8') as file_article:
            for text in article:
                file_article.write(f"{translate_func(text.text.strip())}\n")
                # file_article.write(f"{text.text.strip()}\n")
        create_img(title)


def create_img(title):
    """ Создание img файла из статьи """

    im_1 = Image.open(f"{date}/{title}/img_article.jpeg")
    im_2 = Image.open('CNN.jpg')
    im_1 = im_1.resize((700, 450))
    new_image = Image.new('RGB', (im_1.size[0], im_1.size[1] + im_2.size[1]), (250, 250, 250))
    new_image.paste(im_2, (0, 0))
    new_image.paste(im_1, (0, 246))
    new_image.save(f"{date}/{title}/some_image.jpeg", "JPEG")


def translate_func(message):
    """ Переводчик """

    IAM_TOKEN = 't1.9euelZrLlpDJyomKkI7Hi8vImsiaz-3rnpWajoqKl8bNjZOQnpiVzMyQzc3l8_cUaVFd-e8KM0BY_d3z91QXT1357wozQFj9.5JkUQ6Y70GIfkvxE9YBJMd2Y8PHH5yg6x-jeZp92ZDbOSPODBJB7ErD4hh0sL0bqGuZO4N8J5r83s6mw96KsCQ'
    folder_id = 'b1g0hp1jv0o3lkhso3q1'
    target_language = 'ru'
    text = message

    body = {
        "targetLanguageCode": target_language,
        "texts": text,
        "folderId": folder_id,
    }

    headers = {
        "Content-Type": "application/json",
        "Authorization": "Bearer {0}".format(IAM_TOKEN)
    }

    response = requests.post('https://translate.api.cloud.yandex.net/translate/v2/translate',
                             json=body,
                             headers=headers
                             )
    return response.json()['translations'][0]['text']


def main():
    url = 'https://edition.cnn.com/2023/04/28/world/twilight-zone-life-reduction-climate-scn/index.html'
    title = re.sub('[^\w_.)( -]', '', "Жизнь в 'сумеречной зоне' океана может исчезнуть из-за климатического кризиса")
    create_html_fail(url, title)
    get_article(title)


if __name__ == "__main__":
    main()
